"use strict";(globalThis.webpackChunkdocs_site=globalThis.webpackChunkdocs_site||[]).push([[4228],{6(e,n,t){t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"positioning/what-is-gantral","title":"What is Gantral?","description":"Gantral is an open-source AI Execution Control Plane.","source":"@site/../docs/positioning/what-is-gantral.md","sourceDirName":"positioning","slug":"/positioning/what-is-gantral","permalink":"/positioning/what-is-gantral","draft":false,"unlisted":false,"editUrl":"https://github.com/Rainminds/gantral/tree/main/../docs/positioning/what-is-gantral.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"title":"What is Gantral?"},"sidebar":"tutorialSidebar","previous":{"title":"OPA Integration","permalink":"/guides/opa-integration"},"next":{"title":"What Gantral Is Not","permalink":"/positioning/what-gantral-is-not"}}');var i=t(4848),s=t(8453);const a={sidebar_position:1,title:"What is Gantral?"},o="What Is Gantral?",l={},c=[{value:"The Core Idea: Authority vs. Intelligence",id:"the-core-idea-authority-vs-intelligence",level:2},{value:"How It Works (The Runner Pattern)",id:"how-it-works-the-runner-pattern",level:2},{value:"The Enterprise Governance Crisis",id:"the-enterprise-governance-crisis",level:2},{value:"1. Operational Fragmentation",id:"1-operational-fragmentation",level:3},{value:"Hidden Logic",id:"hidden-logic",level:4},{value:"Siloed Implementations",id:"siloed-implementations",level:4},{value:"2. Broken Chain of Custody",id:"2-broken-chain-of-custody",level:3},{value:"The Self-Reporting Fallacy",id:"the-self-reporting-fallacy",level:4},{value:"The Air Gap",id:"the-air-gap",level:4},{value:"Conceptual Architecture",id:"conceptual-architecture",level:2},{value:"What Gantral Owns (and Does Not)",id:"what-gantral-owns-and-does-not",level:2},{value:"Mental Models",id:"mental-models",level:2},{value:"When Gantral Is (and Is Not) the Right Tool",id:"when-gantral-is-and-is-not-the-right-tool",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",blockquote:"blockquote",br:"br",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",mermaid:"mermaid",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"what-is-gantral",children:"What Is Gantral?"})}),"\n",(0,i.jsxs)(n.p,{children:["Gantral is an ",(0,i.jsx)(n.strong,{children:"open-source AI Execution Control Plane"}),"."]}),"\n",(0,i.jsx)(n.p,{children:"It standardizes how AI-enabled workflows are executed, paused, escalated, approved, overridden, and audited across teams and systems."}),"\n",(0,i.jsx)(n.p,{children:"Gantral exists to solve a specific problem faced by large organizations:"}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"AI adoption breaks execution control and accountability\u2014not just model quality."})}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"As AI tools spread across the software development lifecycle (SDLC) and operational workflows, organizations lose a consistent way to answer fundamental questions:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"What ran?"}),"\n",(0,i.jsx)(n.li,{children:"Under whose authority?"}),"\n",(0,i.jsx)(n.li,{children:"With what configuration?"}),"\n",(0,i.jsx)(n.li,{children:"What human approved or overrode the outcome?"}),"\n",(0,i.jsx)(n.li,{children:"Can this decision be replayed and audited?"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Gantral provides infrastructure-level mechanisms to record and surface answers to these questions."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"the-core-idea-authority-vs-intelligence",children:"The Core Idea: Authority vs. Intelligence"}),"\n",(0,i.jsxs)(n.p,{children:["Gantral introduces a ",(0,i.jsx)(n.strong,{children:"shared execution plane"})," that separates ",(0,i.jsx)(n.strong,{children:"Authority"})," from ",(0,i.jsx)(n.strong,{children:"Reasoning"}),"."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Agents (CrewAI, LangGraph, etc.)"})," provide the ",(0,i.jsx)(n.em,{children:"Intelligence"}),". They plan, reason, and generate code."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Gantral"})," provides the ",(0,i.jsx)(n.em,{children:"Authority"}),". It decides if the agent is allowed to proceed, pauses for human input, and records the outcome."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"This separation prevents AI-driven execution from advancing past governed states without explicit authorization."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"how-it-works-the-runner-pattern",children:"How It Works (The Runner Pattern)"}),"\n",(0,i.jsxs)(n.p,{children:['Gantral does not "host" your agents like a PaaS. It orchestrates them via a ',(0,i.jsx)(n.strong,{children:"Federated Runner"})," model (similar to GitHub Actions runners)."]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Agents"})," run in your own infrastructure (Kubernetes, Lambda, etc.)."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Runners"})," pull tasks from Gantral."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Gantral"}),' enforces policy barriers (e.g., "High Materiality = Pause").']}),"\n",(0,i.jsx)(n.li,{children:"If a human is required, Gantral suspends the workflow. The agent process can exit (Zero CPU)."}),"\n",(0,i.jsx)(n.li,{children:"On approval, Gantral reschedules the task, and the Runner launches a new agent process to complete the work."}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"the-enterprise-governance-crisis",children:"The Enterprise Governance Crisis"}),"\n",(0,i.jsxs)(n.p,{children:["Large organizations face two structural failures when scaling AI: ",(0,i.jsx)(n.strong,{children:"Operational Fragmentation"})," and ",(0,i.jsx)(n.strong,{children:"Broken Chain of Custody"}),"."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"1-operational-fragmentation",children:"1. Operational Fragmentation"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.em,{children:"(The \u201cShadow Runbook\u201d Problem)"})}),"\n",(0,i.jsx)(n.p,{children:"Gantral prevents critical decision logic from being buried inside agent prompts and scripts."}),"\n",(0,i.jsxs)(n.p,{children:["Without a shared execution control plane, platform teams lose visibility into ",(0,i.jsx)(n.strong,{children:"why agents act"}),":"]}),"\n",(0,i.jsx)(n.h4,{id:"hidden-logic",children:"Hidden Logic"}),"\n",(0,i.jsxs)(n.p,{children:["Business-critical rules (e.g., ",(0,i.jsx)(n.em,{children:"\u201cOnly restart DB if latency > 5s\u201d"}),") are embedded in natural-language prompts or agent code, creating ",(0,i.jsx)(n.strong,{children:"\u201cShadow Runbooks\u201d"})," that platform and compliance teams cannot audit, version, or update."]}),"\n",(0,i.jsx)(n.h4,{id:"siloed-implementations",children:"Siloed Implementations"}),"\n",(0,i.jsx)(n.p,{children:"Each team reinvents its own safety checks, approval logic, and escalation paths, leading to inconsistent enforcement of organizational policy."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Gantral decouples decision criteria from agent prompts."}),(0,i.jsx)(n.br,{}),"\n","It allows platform teams to enforce deterministic, centrally governed policy on top of probabilistic agents, without rewriting agent logic."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h3,{id:"2-broken-chain-of-custody",children:"2. Broken Chain of Custody"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.em,{children:"(The \u201cDisconnected Evidence\u201d Problem)"})}),"\n",(0,i.jsxs)(n.p,{children:["Even when humans are involved, the link between ",(0,i.jsx)(n.strong,{children:"facts"})," and ",(0,i.jsx)(n.strong,{children:"approvals"})," is often broken."]}),"\n",(0,i.jsx)(n.h4,{id:"the-self-reporting-fallacy",children:"The Self-Reporting Fallacy"}),"\n",(0,i.jsx)(n.p,{children:"Agents summarize logs, metrics, or tool outputs for humans. These summaries can be incomplete or incorrect. Humans approve actions based on the agent\u2019s narrative, and the audit trail records a \u201cvalid\u201d approval for an invalid justification."}),"\n",(0,i.jsx)(n.h4,{id:"the-air-gap",children:"The Air Gap"}),"\n",(0,i.jsx)(n.p,{children:"An agent recommends an action, and a human executes it manually in a separate system. There is no durable, reviewable link between the execution context at the time of approval and the action taken."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Gantral acts as the execution anchor layer."})}),"\n",(0,i.jsx)(n.p,{children:"It binds:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"the execution context references available at the time of decision"}),"\n",(0,i.jsx)(n.li,{children:"the human approval or override"}),"\n",(0,i.jsx)(n.li,{children:"the enforced execution outcome"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"into a single, immutable execution record."}),"\n",(0,i.jsxs)(n.p,{children:["Gantral does not interpret evidence or tool payloads.",(0,i.jsx)(n.br,{}),"\n","It ensures that ",(0,i.jsx)(n.strong,{children:"no governed action proceeds without a recorded, attributable human decision tied to the exact execution context that justified it"}),"."]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"conceptual-architecture",children:"Conceptual Architecture"}),"\n",(0,i.jsx)(n.mermaid,{value:'graph TB\n    subgraph DevPlane["Developer Control Plane"]\n        direction LR\n        IDE["IDE / Copilot"]\n        Code["Source Code"]\n        Workload["Agentic Workload<br/>(The New Actor)"]\n    end\n\n    subgraph GovPlane["Governance Plane (Gantral)"]\n        direction TB\n        \n        subgraph Ingress["Execution Control"]\n            Proxy["Interceptor Proxy"]\n            Registry["Instance Registry"]\n        end\n\n        subgraph Logic["Decision Layer"]\n            Orch["State Orchestrator<br/>(Temporal)"]\n            Policy["Policy Engine<br/>(OPA)"]\n        end\n\n        subgraph Gates["Authority Gates"]\n            HITL["Human Approval Gate"]\n            Audit["Audit & Compliance Log"]\n        end\n\n        Proxy --\x3e Registry\n        Registry --\x3e Orch\n        Orch --\x3e Policy\n        Policy --\x3e Orch\n        Orch --\x3e HITL\n        HITL --\x3e Audit\n    end\n\n    subgraph ResPlane["Resource Plane"]\n        K8s["Kubernetes Clusters"]\n        Cloud["Cloud Resources"]\n    end\n\n    %% Wiring\n    Workload --\x3e|Tool Call| Proxy\n    Orch --\x3e|Execute| K8s\n    Orch --\x3e|Execute| Cloud\n\n    %% Styling\n    classDef plane fill:#f5faff,stroke:#90a4ae,stroke-width:1px;\n    classDef component fill:#ffffff,stroke:#1565c0,stroke-width:2px,rx:5,ry:5;\n    classDef highlight fill:#e3f2fd,stroke:#1565c0,stroke-width:2px,rx:5,ry:5;\n\n    class DevPlane,GovPlane,ResPlane plane;\n    class IDE,Code,Workload,Proxy,Registry,Orch,Policy,HITL,Audit,K8s,Cloud component;\n    class Workload,Orch highlight;'}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"what-gantral-owns-and-does-not",children:"What Gantral Owns (and Does Not)"}),"\n",(0,i.jsx)(n.p,{children:"Gantral owns execution semantics, not agent intelligence."}),"\n",(0,i.jsx)(n.p,{children:"Gantral provides:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A deterministic execution state machine"}),"\n",(0,i.jsx)(n.li,{children:"Human-in-the-Loop (HITL) as a blocking state transition"}),"\n",(0,i.jsx)(n.li,{children:"Instance-level isolation for audit, cost, and accountability"}),"\n",(0,i.jsx)(n.li,{children:"Declarative control policies (via a pluggable interface)"}),"\n",(0,i.jsx)(n.li,{children:"Immutable execution records with deterministic replay"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Gantral explicitly does not:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Store or manage agent memory"}),"\n",(0,i.jsx)(n.li,{children:"Inspect or reason over tool payloads"}),"\n",(0,i.jsx)(n.li,{children:"Author business logic"}),"\n",(0,i.jsx)(n.li,{children:"Make autonomous decisions"}),"\n",(0,i.jsx)(n.li,{children:"Optimize or route models"}),"\n"]}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:"Gantral may record references to external execution evidence, but it never inspects, interprets, or governs tool behavior."}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Gantral is intentionally boring, predictable, and auditable."}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"mental-models",children:"Mental Models"}),"\n",(0,i.jsx)(n.p,{children:"Gantral can be understood as:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:'"Sudo" for AI'}),' \u2014 An agent tries to execute a command, but Gantral intercepts it and asks, "Are you authorized?"']}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Kubernetes for Semantics"})," \u2014 It manages the ",(0,i.jsx)(n.em,{children:"lifecycle state"})," of AI processes, not just the containers."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Terraform for Process"}),' \u2014 It defines the "Infrastructure of Decision Making" as code.']}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"when-gantral-is-and-is-not-the-right-tool",children:"When Gantral Is (and Is Not) the Right Tool"}),"\n",(0,i.jsx)(n.p,{children:"Gantral is appropriate when actions:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Affect production systems"}),"\n",(0,i.jsx)(n.li,{children:"Have regulatory, financial, or security impact"}),"\n",(0,i.jsx)(n.li,{children:"Require explicit human accountability"}),"\n",(0,i.jsx)(n.li,{children:"Must be auditable months or years later"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Gantral is not required for:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Purely advisory agents"}),"\n",(0,i.jsx)(n.li,{children:"Sandbox or exploratory workflows"}),"\n",(0,i.jsx)(n.li,{children:"Fully reversible or non-material actions"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["See how the architecture ensures safety in the ",(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/architecture/trd",children:"Technical Reference (TRD)"})}),"."]}),"\n",(0,i.jsxs)(n.li,{children:["See it in action with the ",(0,i.jsx)(n.strong,{children:(0,i.jsx)(n.a,{href:"/guides/demo",children:"Persistent Agent Demo"})}),"."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453(e,n,t){t.d(n,{R:()=>a,x:()=>o});var r=t(6540);const i={},s=r.createContext(i);function a(e){const n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);