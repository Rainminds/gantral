"use strict";(globalThis.webpackChunkdocs_site=globalThis.webpackChunkdocs_site||[]).push([[4228],{6(n,e,i){i.r(e),i.d(e,{assets:()=>a,contentTitle:()=>l,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"positioning/what-is-gantral","title":"What is Gantral?","description":"Gantral is an open-source Execution Authority Kernel.","source":"@site/../docs/positioning/what-is-gantral.md","sourceDirName":"positioning","slug":"/positioning/what-is-gantral","permalink":"/positioning/what-is-gantral","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"What is Gantral?"},"sidebar":"docsSidebar","previous":{"title":"Expansion Narrative","permalink":"/positioning/expansion-narrative"},"next":{"title":"What Gantral Is Not","permalink":"/positioning/what-gantral-is-not"}}');var t=i(4848),s=i(8453);const o={title:"What is Gantral?"},l="What Is Gantral?",a={},c=[{value:"Why Gantral Exists",id:"why-gantral-exists",level:2},{value:"The Execution Authority Gap",id:"the-execution-authority-gap",level:2},{value:"Before and After: Execution Authority",id:"before-and-after-execution-authority",level:2},{value:"Before",id:"before",level:3},{value:"After",id:"after",level:3},{value:"The Core Distinction: Authority vs Intelligence",id:"the-core-distinction-authority-vs-intelligence",level:2},{value:"Intelligence",id:"intelligence",level:3},{value:"Authority",id:"authority",level:3},{value:"How Execution Is Governed",id:"how-execution-is-governed",level:2},{value:"What Gantral Owns",id:"what-gantral-owns",level:2},{value:"Policy Advisory Integration (OPA)",id:"policy-advisory-integration-opa",level:2},{value:"Federated Runner Model",id:"federated-runner-model",level:2},{value:"What Gantral Does Not Do",id:"what-gantral-does-not-do",level:2},{value:"When Gantral Is Appropriate",id:"when-gantral-is-appropriate",level:2},{value:"How to Think About Gantral",id:"how-to-think-about-gantral",level:2},{value:"Where to Go Next",id:"where-to-go-next",level:2}];function d(n){const e={a:"a",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",mermaid:"mermaid",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"what-is-gantral",children:"What Is Gantral?"})}),"\n",(0,t.jsxs)(e.p,{children:["Gantral is an ",(0,t.jsx)(e.strong,{children:"open-source Execution Authority Kernel"}),"."]}),"\n",(0,t.jsxs)(e.p,{children:["It provides ",(0,t.jsx)(e.strong,{children:"Deterministic Authority Infrastructure for Scaling AI"}),"."]}),"\n",(0,t.jsxs)(e.p,{children:["Gantral enforces and records ",(0,t.jsx)(e.strong,{children:"execution-time authority"})," in AI-assisted and agentic workflows operating in consequential domains."]}),"\n",(0,t.jsx)(e.p,{children:"Gantral does not evaluate model quality, reasoning correctness, or business logic."}),"\n",(0,t.jsxs)(e.p,{children:["Gantral governs ",(0,t.jsx)(e.strong,{children:"whether execution is admissible"}),"."]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"why-gantral-exists",children:"Why Gantral Exists"}),"\n",(0,t.jsx)(e.p,{children:"AI adoption does not stall because models fail."}),"\n",(0,t.jsx)(e.p,{children:"It stalls when organizations attempt to move from:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["Low-risk experimentation",(0,t.jsx)(e.br,{}),"\n","to"]}),"\n",(0,t.jsx)(e.li,{children:"Consequential, high-impact workflows"}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"When AI systems begin to:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Move money"}),"\n",(0,t.jsx)(e.li,{children:"Modify infrastructure"}),"\n",(0,t.jsx)(e.li,{children:"Change access control"}),"\n",(0,t.jsx)(e.li,{children:"Influence regulatory posture"}),"\n",(0,t.jsx)(e.li,{children:"Trigger irreversible operational outcomes"}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"At that boundary:"}),"\n",(0,t.jsxs)(e.p,{children:["AI can act.",(0,t.jsx)(e.br,{}),"\n","Humans remain accountable."]}),"\n",(0,t.jsx)(e.p,{children:"Most enterprise stacks today can:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Orchestrate workflows"}),"\n",(0,t.jsx)(e.li,{children:"Evaluate policy"}),"\n",(0,t.jsx)(e.li,{children:"Apply guardrails"}),"\n",(0,t.jsx)(e.li,{children:"Log events"}),"\n",(0,t.jsx)(e.li,{children:"Produce dashboards"}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"Very few structurally enforce execution authority."}),"\n",(0,t.jsx)(e.p,{children:"Authority is reconstructed from logs instead of enforced at runtime."}),"\n",(0,t.jsxs)(e.p,{children:["Gantral exists to ensure that when an AI-enabled system performs a consequential action,\nan organization can later determine \u2014 ",(0,t.jsx)(e.strong,{children:"without relying on trust, narrative, or log stitching"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"what executed"}),"\n",(0,t.jsx)(e.li,{children:"under whose authority"}),"\n",(0,t.jsx)(e.li,{children:"with which execution context"}),"\n",(0,t.jsx)(e.li,{children:"whether human approval was required"}),"\n",(0,t.jsx)(e.li,{children:"whether authority can be independently verified"}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"Gantral makes authority:"}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.strong,{children:"explicit \xb7 enforced \xb7 verifiable"})}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"the-execution-authority-gap",children:"The Execution Authority Gap"}),"\n",(0,t.jsx)(e.p,{children:"Most governance failures in AI systems are not caused by models."}),"\n",(0,t.jsx)(e.p,{children:"They are caused by how execution authority is implicitly assumed."}),"\n",(0,t.jsx)(e.p,{children:"Human approval and accountability often exist only as convention:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"pull-request reviews"}),"\n",(0,t.jsx)(e.li,{children:"chat approvals"}),"\n",(0,t.jsx)(e.li,{children:"informal runbooks"}),"\n",(0,t.jsx)(e.li,{children:"screenshots and logs"}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"These mechanisms:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"are not technically enforceable"}),"\n",(0,t.jsx)(e.li,{children:"are not structurally bound to execution"}),"\n",(0,t.jsx)(e.li,{children:"do not produce durable, replayable evidence"}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"At scale, this leads to:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"fragmented execution control across teams"}),"\n",(0,t.jsx)(e.li,{children:"approvals detached from execution context"}),"\n",(0,t.jsx)(e.li,{children:"post-incident reconstruction based on inference"}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"Gantral converts authority from convention into infrastructure."}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"before-and-after-execution-authority",children:"Before and After: Execution Authority"}),"\n",(0,t.jsx)(e.h3,{id:"before",children:"Before"}),"\n",(0,t.jsx)(e.p,{children:"Authority is implied by process and reconstructed after the fact."}),"\n",(0,t.jsx)(e.mermaid,{value:"flowchart TB\n   A[AI Agent or Model\n   \u2022 Policy logic embedded in prompts or code\n   \u2022 Proposes or initiates actions autonomously]\n\n   A --\x3e M[Execution Management\n   \u2022 Automation workflows\n   \u2022 Task runners or orchestration\n   \u2022 Executes without explicit authority checks]\n\n   A -.-> H[Human Reviewer\n   \u2022 Informal notification or review\n   \u2022 No explicit authority boundary]\n\n   H --\x3e T[Human Action Tools\n   \u2022 Dashboards\n   \u2022 Ticketing systems\n   \u2022 Admin consoles]\n\n   M --\x3e R[Action in Real World\n   \u2022 Data changes\n   \u2022 Customer impact\n   \u2022 External side effects]\n\n   T --\x3e R\n\n   R -.-> L[Post-hoc Evidence\n   \u2022 Logs\n   \u2022 Tickets\n   \u2022 Chat records\n   \u2022 Human memory]"}),"\n",(0,t.jsx)(e.p,{children:"Authority is reconstructed from logs and memory."}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h3,{id:"after",children:"After"}),"\n",(0,t.jsx)(e.p,{children:"Authority is enforced as canonical execution state."}),"\n",(0,t.jsx)(e.mermaid,{value:'flowchart TB\n   P[Policy & Governance\n   \u2022 Intent & constraints\n   \u2022 Risk thresholds\n   \u2022 Advisory only]\n\n   subgraph AI["AI & Agent Systems"]\n       LG[LangGraph]\n       VE[Vellum]\n       CC[Claude Cowork]\n   end\n\n   H[Human Operator\n   \u2022 Reviews context\n   \u2022 Exercises judgment\n   \u2022 Accountable actor]\n\n   M[Workflow Orchestration\n   \u2022 Awaits authority]\n\n   subgraph Gantral["Gantral \u2014 Execution-Time Authority"]\n       G[Authority Boundary\n       \u2022 Pause execution\n       \u2022 Require explicit decision\n       \u2022 Approve / Reject / Override\n       \u2022 Record authority deterministically]\n   end\n\n   R[Real-World Actions]\n\n   D[Deterministic Authority Record\n   \u2022 Who authorized\n   \u2022 What was approved\n   \u2022 When & under what conditions]\n\n   LG --\x3e M\n   VE --\x3e M\n   CC --\x3e M\n\n   H --\x3e M\n   P -.-> G\n\n   M --\x3e G\n   G --\x3e|Authorized| R\n   G -.-> D\n   G --\x3e|Pause / Escalate| H'}),"\n",(0,t.jsx)(e.p,{children:"Authority is not inferred."}),"\n",(0,t.jsx)(e.p,{children:"It is enforced."}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"the-core-distinction-authority-vs-intelligence",children:"The Core Distinction: Authority vs Intelligence"}),"\n",(0,t.jsx)(e.p,{children:"Gantral introduces a strict separation between:"}),"\n",(0,t.jsx)(e.h3,{id:"intelligence",children:"Intelligence"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Planning"}),"\n",(0,t.jsx)(e.li,{children:"Reasoning"}),"\n",(0,t.jsx)(e.li,{children:"Tool selection"}),"\n",(0,t.jsx)(e.li,{children:"Action proposals"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"authority",children:"Authority"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Whether execution may proceed"}),"\n",(0,t.jsx)(e.li,{children:"Whether human approval is required"}),"\n",(0,t.jsx)(e.li,{children:"Whether execution must terminate"}),"\n",(0,t.jsx)(e.li,{children:"Whether authority can be proven later"}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"Agents provide intelligence."}),"\n",(0,t.jsx)(e.p,{children:"Gantral enforces authority."}),"\n",(0,t.jsx)(e.p,{children:"This separation is structural, not conceptual."}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"how-execution-is-governed",children:"How Execution Is Governed"}),"\n",(0,t.jsxs)(e.p,{children:["Gantral operates as an ",(0,t.jsx)(e.strong,{children:"execution-time authority layer"}),"."]}),"\n",(0,t.jsx)(e.p,{children:"A typical flow:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"An agent proposes an action."}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Execution reaches a governed boundary."}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"External policy (e.g., OPA) may evaluate conditions (advisory only)."}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Gantral enforces one of:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Continue"}),"\n",(0,t.jsx)(e.li,{children:"Pause for human authority"}),"\n",(0,t.jsx)(e.li,{children:"Reject / Terminate"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Authority transitions are enforced via a deterministic state machine."}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"A commitment artifact is emitted atomically."}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"If authority cannot be enforced and recorded,\nexecution must not proceed."}),"\n",(0,t.jsx)(e.p,{children:"Gantral fails closed."}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"what-gantral-owns",children:"What Gantral Owns"}),"\n",(0,t.jsxs)(e.p,{children:["Gantral owns ",(0,t.jsx)(e.strong,{children:"execution authority invariants"}),", not lifecycle governance."]}),"\n",(0,t.jsx)(e.p,{children:"It provides:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"A deterministic authority state machine"}),"\n",(0,t.jsxs)(e.li,{children:["Explicit ",(0,t.jsx)(e.code,{children:"WAITING_FOR_HUMAN"})," blocking semantics"]}),"\n",(0,t.jsxs)(e.li,{children:["Explicit ",(0,t.jsx)(e.code,{children:"APPROVED / REJECTED / OVERRIDDEN"})," transitions"]}),"\n",(0,t.jsx)(e.li,{children:"Identity binding at authority boundaries"}),"\n",(0,t.jsx)(e.li,{children:"Policy version binding"}),"\n",(0,t.jsx)(e.li,{children:"Workflow version binding"}),"\n",(0,t.jsx)(e.li,{children:"Context snapshot binding"}),"\n",(0,t.jsx)(e.li,{children:"Atomic authority transition + artifact emission"}),"\n",(0,t.jsx)(e.li,{children:"Tamper-evident artifact chains"}),"\n",(0,t.jsx)(e.li,{children:"Log-independent replay"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:["Gantral enforces authority correctness ",(0,t.jsx)(e.strong,{children:"per execution instance"}),"."]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"policy-advisory-integration-opa",children:"Policy Advisory Integration (OPA)"}),"\n",(0,t.jsx)(e.p,{children:"Gantral supports external policy engines in an advisory role."}),"\n",(0,t.jsx)(e.p,{children:"Policy may be authored in:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Open Policy Agent (OPA) / Rego"}),"\n",(0,t.jsx)(e.li,{children:"Custom enterprise policy services"}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"At authority checkpoints:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Policy evaluates conditions."}),"\n",(0,t.jsx)(e.li,{children:"Advisory output is returned."}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.code,{children:"policy_version_id"})," is bound to the execution instance."]}),"\n",(0,t.jsx)(e.li,{children:"Gantral enforces the resulting authority transition structurally."}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"Policy remains advisory.\nAuthority enforcement remains internal and deterministic."}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"federated-runner-model",children:"Federated Runner Model"}),"\n",(0,t.jsx)(e.p,{children:"Gantral uses a federated execution model:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Agents execute in team-owned infrastructure."}),"\n",(0,t.jsx)(e.li,{children:"Gantral does not inspect agent memory or tool payloads."}),"\n",(0,t.jsx)(e.li,{children:"Execution pauses at authority boundaries."}),"\n",(0,t.jsx)(e.li,{children:"Resume signals inject fresh execution context."}),"\n",(0,t.jsx)(e.li,{children:"Long waits allow agent processes to exit cleanly."}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:["Gantral governs ",(0,t.jsx)(e.strong,{children:"permission to execute"}),", not execution mechanics."]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"what-gantral-does-not-do",children:"What Gantral Does Not Do"}),"\n",(0,t.jsx)(e.p,{children:"Gantral explicitly does not:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Manage policy lifecycle"}),"\n",(0,t.jsx)(e.li,{children:"Provide dashboards"}),"\n",(0,t.jsx)(e.li,{children:"Provide cross-workflow analytics"}),"\n",(0,t.jsx)(e.li,{children:"Orchestrate autonomy tiers"}),"\n",(0,t.jsx)(e.li,{children:"Replace orchestration engines"}),"\n",(0,t.jsx)(e.li,{children:"Inspect model prompts or memory"}),"\n",(0,t.jsx)(e.li,{children:"Guarantee regulatory compliance"}),"\n"]}),"\n",(0,t.jsxs)(e.p,{children:["Gantral records and enforces ",(0,t.jsx)(e.strong,{children:"authority"}),", not intent, correctness, or compliance status."]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"when-gantral-is-appropriate",children:"When Gantral Is Appropriate"}),"\n",(0,t.jsx)(e.p,{children:"Gantral is designed for workflows that:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Affect production systems"}),"\n",(0,t.jsx)(e.li,{children:"Have regulatory, financial, or security impact"}),"\n",(0,t.jsx)(e.li,{children:"Require explicit human accountability"}),"\n",(0,t.jsx)(e.li,{children:"Must be auditable months or years later"}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"Gantral is not necessary for:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Advisory-only agents"}),"\n",(0,t.jsx)(e.li,{children:"Exploratory or sandbox workflows"}),"\n",(0,t.jsx)(e.li,{children:"Low-impact, reversible actions"}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"Gantral becomes rational infrastructure when:"}),"\n",(0,t.jsx)(e.p,{children:"\u201cCould we independently prove authority correctness without relying on logs?\u201d"}),"\n",(0,t.jsx)(e.p,{children:"must be answered with confidence."}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"how-to-think-about-gantral",children:"How to Think About Gantral"}),"\n",(0,t.jsx)(e.p,{children:"Useful mental models:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"\u201csudo for AI\u201d"}),"\nExecution is intercepted and requires authority before proceeding."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"\u201cExecution-time constitution\u201d"}),"\nAuthority is enforced as state, not reconstructed from metadata."]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"\u201cChain of custody for automation\u201d"}),"\nAuthority is bound to execution at the moment it occurs."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.h2,{id:"where-to-go-next",children:"Where to Go Next"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Authority & Enforcement"}),"\nSee the ",(0,t.jsx)(e.strong,{children:(0,t.jsx)(e.a,{href:"/architecture/authority-state-machine",children:"Authority State Machine"})})]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Proof & Audit"}),"\nStart with ",(0,t.jsx)(e.strong,{children:(0,t.jsx)(e.a,{href:"/verifiability/",children:"Verifiability Overview"})})]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Technical Semantics"}),"\nRead the ",(0,t.jsx)(e.strong,{children:(0,t.jsx)(e.a,{href:"/architecture/trd",children:"Technical Reference (TRD)"})})]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.hr,{}),"\n",(0,t.jsx)(e.p,{children:"Gantral is intentionally narrow."}),"\n",(0,t.jsx)(e.p,{children:"It does not attempt to make AI correct, ethical, or intelligent."}),"\n",(0,t.jsxs)(e.p,{children:["It makes ",(0,t.jsx)(e.strong,{children:"execution authority deterministic, enforceable, and provable"}),"."]})]})}function h(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453(n,e,i){i.d(e,{R:()=>o,x:()=>l});var r=i(6540);const t={},s=r.createContext(t);function o(n){const e=r.useContext(s);return r.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:o(n.components),r.createElement(s.Provider,{value:e},n.children)}}}]);